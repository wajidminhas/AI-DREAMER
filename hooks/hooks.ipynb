{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm/jshUyPEEJqQq1EGuVch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wajidminhas/AI-DREAMER/blob/main/hooks/hooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BV7nBxCv_GZ",
        "outputId": "525146ae-bef0-43ce-d1cc-aa33a5b35747"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m671.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.4/161.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "IOcwNDKLwFbm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import (\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        ")\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "2AlSEEUkwaxM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import asyncio\n",
        "import random\n",
        "from typing import Any\n",
        "\n",
        "from agents import Agent, RunContextWrapper, RunHooks, Runner, Tool, Usage, function_tool"
      ],
      "metadata": {
        "id": "qR_0YO--woq9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Basic Example (Understand Core Concept)"
      ],
      "metadata": {
        "id": "Hut4qBwIwzGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestHooks(RunHooks):\n",
        "    def __init__(self):\n",
        "        self.event_counter = 0\n",
        "        self.name = \"TestHooks\"\n",
        "\n",
        "    async def on_agent_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(f\"### {self.name} {self.event_counter}: Agent {agent.name} started. Usage: {context.usage}\")\n",
        "\n",
        "    async def on_agent_end(self, context: RunContextWrapper, agent: Agent, output: Any) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(f\"### {self.name} {self.event_counter}: Agent {agent.name} ended. Usage: {context.usage}, Output: {output}\")"
      ],
      "metadata": {
        "id": "5gs9qa-dw2q5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import AgentHooks\n",
        "class TestAgHooks(AgentHooks):\n",
        "    def __init__(self, ag_display_name):\n",
        "        self.event_counter = 0\n",
        "        self.ag_display_name = ag_display_name\n",
        "\n",
        "    async def on_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} started. Usage: {context.usage}\")\n",
        "\n",
        "    async def on_end(self, context: RunContextWrapper, agent: Agent, output: Any) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} ended. Usage: {context.usage}, Output: {output}\")\n",
        ""
      ],
      "metadata": {
        "id": "TL5Q4TKTzabU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_hook = TestHooks()\n",
        "\n",
        "start_agent = Agent(\n",
        "    name=\"Content Moderator Agent\",\n",
        "    instructions=\"You are content moderation agent. Watch social media content received and flag queries that need help or answer. We will answer anything about AI?\",\n",
        "    model=model,\n",
        "    hooks= TestAgHooks(ag_display_name=\"Content Moderator Agent\")\n",
        ")\n",
        "\n",
        "async def main():\n",
        "  result = await Runner.run(\n",
        "      start_agent,\n",
        "      hooks=start_hook,\n",
        "      input=f\"Will Agentic AI Die at end of 2025?.\"\n",
        "  )\n",
        "\n",
        "  print(result.final_output)\n",
        "  # print(result.max_turn())\n",
        "\n",
        "asyncio.run(main())\n",
        "print(\"--end--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QUvRskFxK6Y",
        "outputId": "498df6de-5837-40ae-f327-907e1a5750d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TestHooks 1: Agent Content Moderator Agent started. Usage: Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0)\n",
            "### Content Moderator Agent 1: Agent Content Moderator Agent started. Usage: Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TestHooks 2: Agent Content Moderator Agent ended. Usage: Usage(requests=1, input_tokens=41, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=290, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=331), Output: This query expresses concern about the future of \"Agentic AI.\" While I cannot predict the future, I can offer some general information about Agentic AI and the factors that might influence its development and adoption:\n",
            "\n",
            "Agentic AI refers to AI systems that can act autonomously to achieve specific goals. These systems often involve multiple AI models working together, and are designed to make decisions and take actions without constant human intervention.\n",
            "\n",
            "**Factors that could influence the future of Agentic AI:**\n",
            "\n",
            "*   **Technological advancements:** Continued progress in areas like large language models, reinforcement learning, and robotics will be crucial for the development of more capable and reliable agentic AI systems.\n",
            "*   **Ethical considerations:** As AI systems become more autonomous, it's important to address ethical concerns related to bias, fairness, transparency, and accountability.\n",
            "*   **Regulatory landscape:** Governments and regulatory bodies may introduce new regulations to govern the development and deployment of AI technologies, including agentic AI.\n",
            "*   **Market demand:** The adoption of agentic AI will depend on its ability to solve real-world problems and provide value to businesses and individuals.\n",
            "*   **Public perception:** Public trust in AI technologies will be important for their widespread acceptance and adoption.\n",
            "\n",
            "Given these factors, it is unlikely that agentic AI will simply \"die\" at the end of 2025. However, its development and adoption may evolve in unexpected ways.\n",
            "\n",
            "### Content Moderator Agent 2: Agent Content Moderator Agent ended. Usage: Usage(requests=1, input_tokens=41, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=290, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=331), Output: This query expresses concern about the future of \"Agentic AI.\" While I cannot predict the future, I can offer some general information about Agentic AI and the factors that might influence its development and adoption:\n",
            "\n",
            "Agentic AI refers to AI systems that can act autonomously to achieve specific goals. These systems often involve multiple AI models working together, and are designed to make decisions and take actions without constant human intervention.\n",
            "\n",
            "**Factors that could influence the future of Agentic AI:**\n",
            "\n",
            "*   **Technological advancements:** Continued progress in areas like large language models, reinforcement learning, and robotics will be crucial for the development of more capable and reliable agentic AI systems.\n",
            "*   **Ethical considerations:** As AI systems become more autonomous, it's important to address ethical concerns related to bias, fairness, transparency, and accountability.\n",
            "*   **Regulatory landscape:** Governments and regulatory bodies may introduce new regulations to govern the development and deployment of AI technologies, including agentic AI.\n",
            "*   **Market demand:** The adoption of agentic AI will depend on its ability to solve real-world problems and provide value to businesses and individuals.\n",
            "*   **Public perception:** Public trust in AI technologies will be important for their widespread acceptance and adoption.\n",
            "\n",
            "Given these factors, it is unlikely that agentic AI will simply \"die\" at the end of 2025. However, its development and adoption may evolve in unexpected ways.\n",
            "\n",
            "This query expresses concern about the future of \"Agentic AI.\" While I cannot predict the future, I can offer some general information about Agentic AI and the factors that might influence its development and adoption:\n",
            "\n",
            "Agentic AI refers to AI systems that can act autonomously to achieve specific goals. These systems often involve multiple AI models working together, and are designed to make decisions and take actions without constant human intervention.\n",
            "\n",
            "**Factors that could influence the future of Agentic AI:**\n",
            "\n",
            "*   **Technological advancements:** Continued progress in areas like large language models, reinforcement learning, and robotics will be crucial for the development of more capable and reliable agentic AI systems.\n",
            "*   **Ethical considerations:** As AI systems become more autonomous, it's important to address ethical concerns related to bias, fairness, transparency, and accountability.\n",
            "*   **Regulatory landscape:** Governments and regulatory bodies may introduce new regulations to govern the development and deployment of AI technologies, including agentic AI.\n",
            "*   **Market demand:** The adoption of agentic AI will depend on its ability to solve real-world problems and provide value to businesses and individuals.\n",
            "*   **Public perception:** Public trust in AI technologies will be important for their widespread acceptance and adoption.\n",
            "\n",
            "Given these factors, it is unlikely that agentic AI will simply \"die\" at the end of 2025. However, its development and adoption may evolve in unexpected ways.\n",
            "\n",
            "--end--\n"
          ]
        }
      ]
    }
  ]
}